{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "102c7985"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavideScassola/PML2024/blob/main/./Homeworks/01_homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1X84lNFyii7"
      },
      "source": [
        "## Homework 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIpechcJyii7"
      },
      "source": [
        "Probabilistic Machine Learning -- Spring 2024, UniTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UV1hrXKyii8"
      },
      "source": [
        "### Problem 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlQj0gVWyii8"
      },
      "source": [
        "Let's call $S$ the Bernoulli random variable describing the presence of a certain substance ($S=1$: present, $S=0$: not present) and $T$ the Bernoulli random variable describing the result of the test for detecting that substance ($T=1$: positive, $T=0$: negative).\n",
        "\n",
        "Given:\n",
        "- $P(T=1 | S=1) = 1 - 10^{-4}$\n",
        "- $P(T=1 | S=0) = 10^{-3}$\n",
        "- $P(S = 1) = 10^{-4}$\n",
        "\n",
        "1. Compute the normalized mutual information between $S$ and $T$, that is defined as follows:\n",
        "$$\\text{NMI}[S,T] = \\frac{2 \\cdot \\text{I}[S,T]}{\\text{H}[A] + \\text{H}[B]}$$\n",
        "\n",
        "where $\\text{I}$ indicates the mutual information, and $\\text{H}$ indicates the entropy\n",
        "\n",
        "2. Let's suppose one can repeat the same test $n$ times, and the result of each test will be independent (conditionally given $S$). What is the minimum number of tests $n$ such that the probability of having a false positive after getting $n$ positive tests is less than $10^{-6}$ ?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution:\n",
        "\n",
        "S and T are discrete random variables, so the entropy is defined as $$H[p]=-\\sum_ip(x_i)\\log p(x_i)$$\n",
        "The mutual information is defined as $$I[x,y]=KL[p(x,y)||p(x)p(y)]$$"
      ],
      "metadata": {
        "id": "WApw3GT40gRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "P_T1_given_S1 = 1 - 10**-4  # P(T = 1 | S = 1)\n",
        "P_T1_given_S0 = 10**-3     # P(T = 1 | S = 0)\n",
        "P_S1 = 10**-4             # P(S = 1)\n",
        "P_S0 = 1 - P_S1                               # P(S = 0)\n",
        "P_T1 = P_T1_given_S1 * P_S1 + P_T1_given_S0 * P_S0 # P(T = 1)\n",
        "P_T0_given_S1 = 1 - P_T1_given_S1              # P(T = 0 | S = 1)\n",
        "P_T0_given_S0 = 1 - P_T1_given_S0              # P(T = 0 | S = 0)\n",
        "P_T0 = 1 - P_T1                               # P(T = 0)\n",
        "\n",
        "P_S1T1 = P_T1_given_S1 * P_S1   # P(S=1, T=1)\n",
        "P_S1T0 = P_T0_given_S1 * P_S1  # P(S=1, T=0)\n",
        "P_S0T1 = P_T1_given_S0 * P_S0   # P(S=0, T=1)\n",
        "P_S0T0 = P_T0_given_S0 * P_S0  # P(S=0, T=0)\n",
        "\n",
        "# Entropy of S\n",
        "H_S = - (P_S1 * np.log2(P_S1) + P_S0 * np.log2(P_S0))\n",
        "\n",
        "# Entropy of T\n",
        "H_T = - (P_T1 * np.log2(P_T1) + P_T0 * np.log2(P_T0))\n",
        "\n",
        "# Mutual information\n",
        "I_ST = (P_S1T1 * np.log2(P_S1T1 / (P_S1 * P_T1)) +\n",
        "        P_S1T0 * np.log2(P_S1T0 / (P_S1 * P_T0)) +\n",
        "        P_S0T1 * np.log2(P_S0T1 / (P_S0 * P_T1)) +\n",
        "        P_S0T0 * np.log2(P_S0T0 / (P_S0 * P_T0)))\n",
        "\n",
        "# Normalized mutual information\n",
        "NMI = 2 * I_ST / (H_S + H_T)\n",
        "\n",
        "print(f\"The Normalized Mutual Information (NMI) is: {NMI}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZ2ON9gIDzVD",
        "outputId": "617d8295-7298-4574-e7f5-23c4bc31006f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Normalized Mutual Information (NMI) is: 0.14266985665645654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given that the results of each test are independent, the probability of having n false positive tests is $$P(T=1|S=0)^n$$\n",
        "Given that $$P(T=1|S=0)=10^{-3}$$\n",
        "We want $P(T=1|S=0)^n<10^{-6}$ so $$n\\log10^{-3} < \\log 10^{-6} $$ $$n > \\frac{-6}{-3}$$ $$ n > 2$$ So we have to take at least 3 tests."
      ],
      "metadata": {
        "id": "aSpQoX2gKGA6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ0BT5QSyii9"
      },
      "source": [
        "### Problem 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCWkaNyuyii9"
      },
      "source": [
        "It's night and you are looking into the sky waiting to see a falling star. After the first hour you still haven't seen anything, so you check online and find two sources $s_1$ and $s_2$. According to $s_1$ the waiting time is distributed as $p_1(t) = 2e^{-2t}$, according to $s_2$ it's $p_2(t) = 0.3e^{-0.3t}$.\n",
        "\n",
        "Assuming (only) one of the two is correct and that at first you don't trust one more than the other ( $P(s_1 \\text{ is correct}) = P(s_2 \\text{ is correct}) = 0.5$ ):\n",
        "- Which one of the two sources do you believe more after the first hour? Can you quantify it?\n",
        "- What is the probability of seeing the first falling star in the next 1 hour?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution:\n",
        "\n",
        "The probability to observe a falling star in the first hour, given that the first source is correct is $(s_1=1)$\n",
        "$$p(t \\le 1 | s_1=1) = \\int_0^12e^{-2t}dt \\sim 0.86$$\n",
        "The probability to observe a falling star in the first hour, given that the second source is correct is $(s_2=1)$\n",
        "$$p(t \\le 1 | s_2=1) = \\int_0^10.3e^{-0.3t}dt \\sim 0.26$$\n",
        "So it seems more probable to be correct the second source, given the fact that I didn't see a falling star in the first our.\n",
        "\n",
        "The probability of observe a falling star between the first and the second hour is the same as the probability of observe it in the first hour because of the absence of memory of the distributions examined. Let's prove it:\n",
        "\n",
        "$$p(t \\lt 2 | t\\gt 1 \\cap s_1=1)=\\frac{p(t \\lt 2 \\cap t\\gt 1 \\cap s_1=1I}{p(t \\gt 1  \\cap s_1=1)}=\\frac{p(1 \\lt t \\lt 2 \\cap s_1=1)}{p(t \\gt 1  \\cap s_1=1)}\n",
        "= \\frac{\\int_1^22e^{-2t}dt}{\\int_1^\\infty2e^{-2t}dt} \\sim 0.86$$\n",
        "\n",
        "$$p(t \\lt 2 | t\\gt 1 \\cap s_2=1)=\\frac{p(t \\lt 2 \\cap t\\gt 1 \\cap s_2=1)}{p(t \\gt 1  \\cap s_2=1)}=\\frac{p(1 \\lt t \\lt 2 \\cap s_2=1)}{p(t \\gt 1  \\cap s_2=1)}\n",
        "= \\frac{\\int_1^20.3e^{-0.3t}dt}{\\int_1^\\infty0.3e^{-0.3t}dt} \\sim 0.26$$"
      ],
      "metadata": {
        "id": "9Ac5M9jUZTVU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-feSTJV1yii-"
      },
      "source": [
        "### Problem 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPifswmEyii-"
      },
      "source": [
        "You enrolled to a small tennis tournament organized by your university, that has only other three participants: let's call them $A$, $B$ and $C$.\n",
        "Your first match will be against $A$, and it's scheduled after the match between $A$ and $B$ and the match between $B$ and $C$.\n",
        "\n",
        "Assuming the result of a match $M \\in \\{0,1\\}$ between two players $X$ and $Y$ ($M=1$ means $X$ won, $M=0$ means $Y$ won) is described by the following model:\n",
        "\n",
        "$$M \\sim Bern(p)$$\n",
        "\n",
        "where $p = f(2(S_x - S_y))$ with $f(k) = \\frac{1}{1 + e^{-k}}$ and\n",
        "\n",
        "$$S_i \\sim \\mathcal{N}(0,1)$$\n",
        "\n",
        "is the \"latent\" skill of player $i$ (always the same for every match that player $i$ plays)\n",
        "\n",
        "1. Show a bayesian network describing the relationship between all the involved random variables.\n",
        "2. Make a model in pyro describing the stochastic process.\n",
        "3. Estimate by simulation the probability of (you) winninng against $A$, given that $A$ won against $B$ and $B$ won against $C$. Use exactly 30000 samples and call `set_seed()` before sampling.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution:\n",
        "\n",
        "1_ $$\\begin{matrix}\n",
        "  S_A & S_B & S_C \\\\\n",
        "  | & | & | \\\\\n",
        "  A &→ B &→ C\n",
        "\\end{matrix}$$"
      ],
      "metadata": {
        "id": "ZFEbLeNZYG2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2_"
      ],
      "metadata": {
        "id": "0JsdcR3ycY72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyro-ppl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWIQDf8PUkqi",
        "outputId": "a80fa031-26df-483c-d03b-24469ee39760"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyro-ppl in /usr/local/lib/python3.10/dist-packages (1.9.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl) (3.3.0)\n",
            "Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl) (0.1.2)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl) (4.66.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro-ppl) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro-ppl) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro-ppl) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro-ppl) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro-ppl) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro-ppl) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro-ppl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro-ppl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro-ppl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro-ppl) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro-ppl) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro-ppl) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro-ppl) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro-ppl) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro-ppl) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro-ppl) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro-ppl) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro-ppl) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0->pyro-ppl) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0->pyro-ppl) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0->pyro-ppl) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iUH5D58Fyii_"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import pyro\n",
        "import pyro.distributions as dist\n",
        "import seaborn as sns\n",
        "\n",
        "def set_seed():\n",
        "    seed = 0\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def funct(k):\n",
        "    return 1/(1+np.exp(-k))\n",
        "\n",
        "# Define the model\n",
        "def tennis_model(n : int = 1, obs1=None, obs2=None):\n",
        "    # Latent skill levels of players\n",
        "    S_A = pyro.sample(\"S_A\", dist.Normal(0, 1))#, sample_shape=(n,))\n",
        "    S_B = pyro.sample(\"S_B\", dist.Normal(0, 1))#, sample_shape=(n,))\n",
        "    S_C = pyro.sample(\"S_C\", dist.Normal(0, 1))#, sample_shape=(n,))\n",
        "    S_me = pyro.sample(\"S_me\", dist.Normal(0, 1))#, sample_shape=(n,))\n",
        "\n",
        "    # Compute match outcomes\n",
        "    p_A_vs_B = funct(2*(S_A-S_B))\n",
        "    A_vs_B = pyro.sample(\"A_vs_B\", dist.Bernoulli(p_A_vs_B), sample_shape=(n,), obs=obs1)\n",
        "\n",
        "    p_B_vs_C = funct(2*(S_B-S_C))\n",
        "    B_vs_C = pyro.sample(\"B_vs_C\", dist.Bernoulli(p_B_vs_C), sample_shape=(n,), obs=obs2)\n",
        "\n",
        "    # Infer the outcome of your match against A based on outcomes of previous matches\n",
        "    p_me_vs_A = funct(2*(S_me-S_A))\n",
        "    me_vs_A = pyro.sample(\"me_vs_A\", dist.Bernoulli(p_me_vs_A), sample_shape=(n,))\n",
        "\n",
        "    return {\n",
        "        \"A_vs_B\": A_vs_B,\n",
        "        \"B_vs_C\": B_vs_C,\n",
        "        \"me_vs_A\": me_vs_A\n",
        "    }\n",
        "\n",
        "pyro.render_model(tennis_model, model_args=(1, torch.tensor(1.0), torch.tensor(1.0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "ZF07_Gw8ZSAd",
        "outputId": "1926afa2-fc67-40d3-d95c-97c753a83108"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"299pt\" height=\"116pt\"\n viewBox=\"0.00 0.00 298.84 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-112 294.84,-112 294.84,4 -4,4\"/>\n<!-- S_A -->\n<g id=\"node1\" class=\"node\">\n<title>S_A</title>\n<ellipse fill=\"white\" stroke=\"black\" cx=\"110.85\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"110.85\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">S_A</text>\n</g>\n<!-- A_vs_B -->\n<g id=\"node5\" class=\"node\">\n<title>A_vs_B</title>\n<ellipse fill=\"gray\" stroke=\"black\" cx=\"151.85\" cy=\"-18\" rx=\"39.79\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"151.85\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">A_vs_B</text>\n</g>\n<!-- S_A&#45;&gt;A_vs_B -->\n<g id=\"edge1\" class=\"edge\">\n<title>S_A&#45;&gt;A_vs_B</title>\n<path fill=\"none\" stroke=\"black\" d=\"M120.36,-72.76C125.3,-64.32 131.46,-53.8 137.02,-44.31\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"140.07,-46.03 142.1,-35.63 134.03,-42.49 140.07,-46.03\"/>\n</g>\n<!-- me_vs_A -->\n<g id=\"node7\" class=\"node\">\n<title>me_vs_A</title>\n<ellipse fill=\"white\" stroke=\"black\" cx=\"44.85\" cy=\"-18\" rx=\"44.69\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"44.85\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">me_vs_A</text>\n</g>\n<!-- S_A&#45;&gt;me_vs_A -->\n<g id=\"edge5\" class=\"edge\">\n<title>S_A&#45;&gt;me_vs_A</title>\n<path fill=\"none\" stroke=\"black\" d=\"M96.85,-74.15C88.29,-65.07 77.13,-53.24 67.35,-42.87\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"69.61,-40.17 60.21,-35.29 64.52,-44.97 69.61,-40.17\"/>\n</g>\n<!-- S_B -->\n<g id=\"node2\" class=\"node\">\n<title>S_B</title>\n<ellipse fill=\"white\" stroke=\"black\" cx=\"182.85\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"182.85\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">S_B</text>\n</g>\n<!-- S_B&#45;&gt;A_vs_B -->\n<g id=\"edge2\" class=\"edge\">\n<title>S_B&#45;&gt;A_vs_B</title>\n<path fill=\"none\" stroke=\"black\" d=\"M175.5,-72.41C171.92,-64.34 167.54,-54.43 163.52,-45.35\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"166.6,-43.68 159.36,-35.96 160.2,-46.52 166.6,-43.68\"/>\n</g>\n<!-- B_vs_C -->\n<g id=\"node6\" class=\"node\">\n<title>B_vs_C</title>\n<ellipse fill=\"gray\" stroke=\"black\" cx=\"251.85\" cy=\"-18\" rx=\"38.99\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"251.85\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">B_vs_C</text>\n</g>\n<!-- S_B&#45;&gt;B_vs_C -->\n<g id=\"edge3\" class=\"edge\">\n<title>S_B&#45;&gt;B_vs_C</title>\n<path fill=\"none\" stroke=\"black\" d=\"M197.14,-74.5C206.29,-65.22 218.37,-52.97 228.84,-42.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"231.6,-44.53 236.12,-34.95 226.61,-39.61 231.6,-44.53\"/>\n</g>\n<!-- S_C -->\n<g id=\"node3\" class=\"node\">\n<title>S_C</title>\n<ellipse fill=\"white\" stroke=\"black\" cx=\"254.85\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"254.85\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">S_C</text>\n</g>\n<!-- S_C&#45;&gt;B_vs_C -->\n<g id=\"edge4\" class=\"edge\">\n<title>S_C&#45;&gt;B_vs_C</title>\n<path fill=\"none\" stroke=\"black\" d=\"M254.1,-71.7C253.77,-63.98 253.38,-54.71 253.01,-46.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"256.5,-45.95 252.58,-36.1 249.51,-46.25 256.5,-45.95\"/>\n</g>\n<!-- S_me -->\n<g id=\"node4\" class=\"node\">\n<title>S_me</title>\n<ellipse fill=\"white\" stroke=\"black\" cx=\"34.85\" cy=\"-90\" rx=\"31.4\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"34.85\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">S_me</text>\n</g>\n<!-- S_me&#45;&gt;me_vs_A -->\n<g id=\"edge6\" class=\"edge\">\n<title>S_me&#45;&gt;me_vs_A</title>\n<path fill=\"none\" stroke=\"black\" d=\"M37.32,-71.7C38.42,-63.98 39.74,-54.71 40.97,-46.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"44.45,-46.5 42.4,-36.1 37.52,-45.51 44.45,-46.5\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7be11e3db550>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3_"
      ],
      "metadata": {
        "id": "ed1vDgJYcbfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the model\n",
        "set_seed()\n",
        "samples = tennis_model(3000)\n",
        "df_samples = pd.DataFrame({key: value.numpy() for key, value in samples.items()})\n",
        "# Count the number of times you win against A given A won against B and B won against C\n",
        "win_count = ((df_samples[\"me_vs_A\"] == 1) & (df_samples[\"A_vs_B\"] == 1) & (df_samples[\"B_vs_C\"] == 1)).sum()\n",
        "# Calculate the probability of winning against A\n",
        "probability = win_count / len(df_samples)\n",
        "print(\"Probability of winning against A:\", probability)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbfqTvxVZnEJ",
        "outputId": "e907eb7b-383b-4354-9ca2-93b1ae35fbad"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of winning against A: 0.122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olmjpuKryijB"
      },
      "source": [
        "### Problem 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wRzRmdxyijC"
      },
      "source": [
        "Given a list of $n$ random variables $X_1, X_2, \\ldots, X_n$ such that:\n",
        "$$\\forall{i}, \\ p(x_{i+2} | x_{i+1}, x_{i}) = p(x_{i+2} | x_{i+1})$$\n",
        "\n",
        "prove:\n",
        "$$\\forall{i}, \\ p(x_{i-2} | x_{i-1}, x_{i}) = p(x_{i-2} | x_{i-1})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution:\n",
        "\n",
        "$$\\forall i \\quad p(x_{i+2}|x_{x+1},x_{i})=p(x_{i+2}|x_{x+1}) \\quad \\Rightarrow \\quad \\forall i \\quad x_{i+2} \\perp x_{i}|x_{x+1}\\\\\n",
        "p(x_{i-2}|x_{i-1},x_{i})=\\frac{p(x_{i-2},x_{i-1},x_{i})}{p(x_{i-1},x_{i})}=\\frac{p(x_{i},x_{i-2}|x_{i-1})p(x_{i-1})}{p(x_{i}|x_{i-1})p(x_{i-1})}=\\\\\n",
        "=\\frac{p(x_{i},x_{i-2}|x_{i-1})}{p(x_{i}|x_{i-1})} \\quad x_{i}\\perp x_{i-2}|x_{i-1} \\quad \\Rightarrow \\quad =\\frac{p(x_{i}|x_{i-1})p(x_{i-2}|x_{i-1})}{p(x_{i}|x_{i-1})}=p(x_{i-2}|x_{i-1})\n",
        "$$"
      ],
      "metadata": {
        "id": "7EMOErPrcWBR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8htsI73HyijC"
      },
      "source": [
        "### Problem 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGX-0vI3yijD"
      },
      "source": [
        "A chocolate easter egg contains 1 of $N$ possible different surprises. Assuming all surprises are equally probable, how many eggs do you expect you have to buy if you want to collect all $N$ possible surprises?\n",
        "\n",
        "Finally, compute it for $N=100$ (using python)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def expected_eggs_to_collect_all(N):\n",
        "    expected_eggs = N * sum(1 / i for i in range(1, N + 1))\n",
        "    return expected_eggs\n",
        "\n",
        "N = 100\n",
        "expected_eggs = expected_eggs_to_collect_all(N)\n",
        "print(\"Expected number of eggs to collect all\", N, \"possible surprises:\", expected_eggs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G13trcM8FNB0",
        "outputId": "a61ea1de-1089-4e95-e0a4-4e5e606b7098"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected number of eggs to collect all 100 possible surprises: 518.737751763962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the minimum number of eggs to open is 519"
      ],
      "metadata": {
        "id": "rOcshShUF20S"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjFnb1poyijD"
      },
      "source": [
        "### Problem 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RgxfzzEyijE"
      },
      "source": [
        "In the notebook “Exact inference with Belief Propagation”, we implemented the forward pass of the sum-product algorithm in order to compute the marginal distribution of a variable.  \n",
        "1. Add to the class “Messages” a method “forward” which computes the forward pass without calculating the marginal distribution of a given variable\n",
        "2. Add to the class “Messages” a method “backward” which computes the backward pass\n",
        "3. Add to the class “Messages” a method “belief_propagation” which executes first the forward pass and then the backward pass and uses the messages to compute  all the marginals. Return a dictionary containing the variable names and the corresponding marginals.\n",
        "4. Use this method to compute the marginals of the variables of the factor graph described on page 43 of the notes of the course.\n",
        "\n",
        "For this exercise, please submit the notebook 04_exact_inference.ipybn with your additional code."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Messages(object):\n",
        "    def __init__(self):\n",
        "        self.messages = {}\n",
        "\n",
        "    def _variable_to_factor_messages(self, variable: Variable, factor: Factor):\n",
        "        # Take the product over all incoming factors into this variable except the variable\n",
        "        incoming_messages = [\n",
        "            self.factor_to_variable_message(neighbor_factor, variable)\n",
        "            for neighbor_factor in variable.neighbors\n",
        "            if neighbor_factor.name != factor.name\n",
        "        ]\n",
        "\n",
        "        # If there are no incoming messages, this is 1 (BASE CASE)\n",
        "        return np.prod(incoming_messages, axis=0)\n",
        "\n",
        "    def _factor_to_variable_messages(self, factor, variable: Variable):\n",
        "        #reinstantiate to obtain a deep copy\n",
        "        factor_dist = Distribution(factor.distribution.probs, factor.distribution.axes_labels)\n",
        "\n",
        "        for neighbor_variable in factor.neighbors:\n",
        "            if neighbor_variable.name == variable.name:\n",
        "                continue\n",
        "            #Retrieve the incoming message and multiply the conditional distribution of the factor with the message\n",
        "            incoming_message = self.variable_to_factor_messages(neighbor_variable, factor)\n",
        "            factor_dist = multiply(factor_dist, Distribution(incoming_message, [neighbor_variable.name]))\n",
        "\n",
        "        # Sum over the axes that aren't `variable`\n",
        "        factor_dist = factor_dist.probs\n",
        "        other_axes = factor.distribution.get_other_axes_from(variable.name)\n",
        "        return np.squeeze(np.sum(factor_dist, axis=other_axes))\n",
        "\n",
        "\n",
        "    def marginal(self, variable):\n",
        "        # p(variable) is proportional to the product of incoming messages to variable.\n",
        "        unnorm_p = np.prod([\n",
        "            self.factor_to_variable_message(neighbor_factor, variable)\n",
        "            for neighbor_factor in variable.neighbors\n",
        "        ], axis=0)\n",
        "\n",
        "        # At this point, we can normalize this distribution\n",
        "        return unnorm_p/np.sum(unnorm_p)\n",
        "\n",
        "    def variable_to_factor_messages(self, variable, factor):\n",
        "        message_name = (variable.name, factor.name)\n",
        "        if message_name not in self.messages:\n",
        "            self.messages[message_name] = self._variable_to_factor_messages(variable, factor)\n",
        "        return self.messages[message_name]\n",
        "\n",
        "    def factor_to_variable_message(self, factor, variable):\n",
        "        message_name = (factor.name, variable.name)\n",
        "        if message_name not in self.messages:\n",
        "            self.messages[message_name] = self._factor_to_variable_messages(factor, variable)\n",
        "        return self.messages[message_name]\n",
        "\n",
        "    def forward(self, variable):\n",
        "        for f in variable.neighbors:\n",
        "          for v in f.neighbors:\n",
        "            if v.name != variable.name:\n",
        "              self.variable_to_factor_message(v, f)\n",
        "          self.factor_to_variable_message(f, variable)\n",
        "\n",
        "    def backward(self, root):\n",
        "        m = Messages()\n",
        "        for f in root.neighbors:\n",
        "          if (root.name, f.name) in m:\n",
        "            continue\n",
        "          else:\n",
        "            for v in f.neighbors:\n",
        "              if v.name==root.name:\n",
        "                continue\n",
        "              else:\n",
        "                if (v.name, f.name) in m:\n",
        "                  continue\n",
        "                else:\n",
        "                  self.variable_to_factor_message(root, f)\n",
        "                  self.factor_to_variable_message(f, v)\n",
        "\n",
        "            backward(v)\n"
      ],
      "metadata": {
        "id": "sSekxsWfQvfU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}